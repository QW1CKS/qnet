name: CI
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy
      - uses: actions/setup-go@v4
        with:
          go-version: '1.21'
          cache-dependency-path: linter/go.sum
      - name: Build Rust
        run: |
          cargo build --workspace --all-targets
          cargo build -p htx --features rustls-config --examples
      - name: Build Go Linter
        run: |
          cd linter
          go build -o qnet-lint ./cmd/qnet-lint/
      - name: Test
        run: |
          cargo test --workspace --all-features
          cargo test -p htx --features rustls-config
      - name: Lint
        run: |
          cargo clippy --workspace --all-targets --all-features -- -D warnings
          cargo fmt --all -- --check
      - name: Generate SBOM
        continue-on-error: true
        run: |
          # Install syft for SBOM generation
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin
          syft packages . -o json --file sbom.json
      - name: Generate checksums
        run: |
          cd target/debug
          # Only hash regular files in this directory
          find . -maxdepth 1 -type f -exec sha256sum {} + > checksums.txt
          cd ../../linter
          sha256sum qnet-lint >> ../target/debug/checksums.txt
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: qnet-artifacts
          path: |
            target/debug/
            linter/qnet-lint
            sbom.json

  perf-guard:
    name: Perf guard (quick benches)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: dtolnay/rust-toolchain@stable
      - name: Prepare base checkout
        run: |
          BASE_SHA=${{ github.event.pull_request.base.sha }}
          echo "Base SHA: $BASE_SHA"
          git clone . _base
          cd _base
          git checkout $BASE_SHA
      - name: Run benches (base)
        env:
          RUSTFLAGS: "-C target-cpu=native"
        run: |
          cd _base
          cargo bench --features perf-bench --no-default-features || true
          mkdir -p ../artifacts/base-criterion
          [ -d target/criterion ] && cp -r target/criterion/* ../artifacts/base-criterion/ || true
      - name: Run benches (PR)
        env:
          RUSTFLAGS: "-C target-cpu=native"
        run: |
          cargo bench --features perf-bench --no-default-features || true
          mkdir -p artifacts/criterion
          [ -d target/criterion ] && cp -r target/criterion/* artifacts/criterion/ || true
      - name: Check perf override
        id: override
        run: |
          python3 - << 'PY'
          import json, os
          evt = json.load(open(os.environ['GITHUB_EVENT_PATH']))
          labels = [l.get('name','').lower() for l in evt.get('pull_request',{}).get('labels',[])]
          body = (evt.get('pull_request',{}).get('body') or '').lower()
          override = ('perf-override' in labels) or ('perf-override:' in body)
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"enabled={'true' if override else 'false'}\n")
          print('Perf override:', override)
          PY
      - name: Compare and enforce thresholds
        env:
          PERF_OVERRIDE: ${{ steps.override.outputs.enabled }}
        run: |
          python3 - << 'PY'
          import os, json
          base_root = 'artifacts/base-criterion'
          new_root = 'artifacts/criterion'
          max_latency_regress = 1.15
          min_throughput_ratio = 0.90
          regressions = []
          for root, dirs, files in os.walk(new_root):
              for d in dirs:
                  # look for estimates.json in new and base of same bench
                  bench_path = os.path.join(root, d)
                  if not os.path.isdir(bench_path):
                      continue
                  est_new = os.path.join(bench_path, 'new', 'estimates.json')
                  if not os.path.exists(est_new):
                      # Criterion quick run may not have 'new', use estimates.json at bench root
                      est_new = os.path.join(bench_path, 'estimates.json')
                  # find corresponding base estimates by relative path
                  rel = os.path.relpath(bench_path, new_root)
                  base_path = os.path.join(base_root, rel)
                  est_base = os.path.join(base_path, 'base', 'estimates.json')
                  if not os.path.exists(est_base):
                      est_base = os.path.join(base_path, 'estimates.json')
                  if os.path.exists(est_new) and os.path.exists(est_base):
                      try:
                          bn = json.load(open(est_new))
                          bb = json.load(open(est_base))
              new_mean = bn['mean']['point_estimate']
              base_mean = bb['mean']['point_estimate']
              # latency regression (>15% slower)
              lat_ratio = new_mean / base_mean if base_mean > 0 else 1.0
              if lat_ratio > max_latency_regress:
                regressions.append((rel, lat_ratio, 'latency'))
              # throughput drop (>10%)
              thr_ratio = base_mean / new_mean if new_mean > 0 else 1.0
              if thr_ratio < min_throughput_ratio:
                regressions.append((rel, thr_ratio, 'throughput'))
                      except Exception as e:
                          pass
      if regressions:
        print('Performance regressions detected:')
        for name, ratio, kind in regressions:
          if kind == 'latency':
            print(f'  {name}: {ratio:.2f}x slower (latency)')
          else:
            print(f'  {name}: throughput ratio {ratio:.2f} (< 0.90)')
        import os
        if os.environ.get('PERF_OVERRIDE','false').lower() == 'true':
          print('PERF OVERRIDE active â€” not failing build.')
        else:
          raise SystemExit(1)
          else:
              print('Perf guard passed')
          PY

  fuzz-and-coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@nightly
      - name: Install cargo-fuzz and tarpaulin
        run: |
          cargo install --locked cargo-fuzz
          cargo install --locked cargo-tarpaulin
      - name: Build fuzz targets
        if: ${{ hashFiles('fuzz/**/Cargo.toml') != '' }}
        run: |
          cd fuzz
          cargo +nightly fuzz build
      - name: Run fuzzers (time-boxed)
        if: ${{ hashFiles('fuzz/**/Cargo.toml') != '' }}
        run: |
          set -e
          cd fuzz
          # Each for ~15 minutes => ~30 minutes total
          set +e
          timeout 15m cargo +nightly fuzz run framing_decode -- -runs=0
          code=$?
          if [ $code -ne 0 ] && [ $code -ne 124 ]; then echo "framing_decode crashed (exit $code)"; exit $code; fi
          timeout 15m cargo +nightly fuzz run noise_handshake -- -runs=0
          code=$?
          if [ $code -ne 0 ] && [ $code -ne 124 ]; then echo "noise_handshake crashed (exit $code)"; exit $code; fi
          set -e
      - name: Coverage (core-framing)
        run: |
          # Focus coverage on core-framing; allow test-only instrumentation. Do not fail build on low coverage.
          cargo tarpaulin -p core-framing --engine=llvm --line --out Xml --timeout 180 --ignore-tests || true
          if [ -f cobertura.xml ]; then mv cobertura.xml cobertura-core-framing.xml; fi
          if [ -f cobertura-core-framing.xml ]; then
            cov=$(grep -o 'line-rate="[0-9.]*"' cobertura-core-framing.xml | head -n1 | sed -E 's/.*="([0-9.]+)"/\1/')
            echo "core-framing line coverage: $cov"
          fi
      - name: Coverage (htx)
        run: |
          cargo tarpaulin -p htx --engine=llvm --line --out Xml --timeout 180 --ignore-tests || true
          if [ -f cobertura.xml ]; then mv cobertura.xml cobertura-htx.xml; fi
          if [ -f cobertura-htx.xml ]; then
            cov=$(grep -o 'line-rate="[0-9.]*"' cobertura-htx.xml | head -n1 | sed -E 's/.*="([0-9.]+)"/\1/')
            echo "htx line coverage: $cov"
          fi

